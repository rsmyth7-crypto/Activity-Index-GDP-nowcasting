# -*- coding: utf-8 -*-
"""1.datacleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nFyIsPN49RT8YbLAwnPjnQqvvzFrsX6J

# Create Folders

In order to organise the project, I have included the following folder system
"""

import os

project_root = "/content/economic_search_project"

folders = [
    "data/raw",
    "data/processed",
    "analysis",
    "notebooks",
    "results",
    "models",
    "docs",
]

for folder in folders:
    os.makedirs(os.path.join(project_root, folder), exist_ok=True)

project_root

"""# Gather Data

### **Upload quarterly GDP**

Ensure NAQ03.20251127T121156.csv is uploaded to the Collab file base, this data can be located in the Github folder called 'files'
"""

import os
import shutil


# IMPORTANT: Please upload the file `NAQ03.20251127T121156.csv` to the current Colab environment.
# The cell below will then move it to the correct project folder.

gdp_filename = "NAQ03.20251127T121156.csv"  # This is based on current name of the GDP data file

project_root = '/content/economic_search_project'
source_path = os.path.join('/content', gdp_filename)
target_folder = os.path.join(project_root, 'data/raw')
destination_path = os.path.join(target_folder, gdp_filename)

# Ensure the target folder exists
os.makedirs(target_folder, exist_ok=True)

# Check if the file has been uploaded to the Colab environment
if os.path.exists(source_path):
    # Check if the file is already in the destination
    if os.path.exists(destination_path):
        print(f'GDP file "{gdp_filename}" already exists at "{destination_path}". No move needed.')
    else:
        try:
            shutil.move(source_path, destination_path)
            print(f'Successfully moved GDP file "{gdp_filename}" to "{destination_path}"')
        except Exception as e:
            print(f"Error moving file: {e}")
            raise
else:
    print(f"Error: GDP file '{gdp_filename}' not found in '/content/'.")
    print("Please ensure you have manually uploaded the file to the Colab environment before running this cell.")
    raise FileNotFoundError(f"GDP file '{gdp_filename}' not found at {source_path}")

# The variable 'destination_path' is now set and ready for use in subsequent cells (e.g., pd.read_csv).

"""### **Collecting data on google search trends using hospitality key words and saving as CSV file in raw data folder**




"""

!pip install pytrends
from pytrends.request import TrendReq
import pandas as pd
import os

# Using the pytrends API ensures the model stays up to date with the high
# frequency information
pytrends = TrendReq()

#This selection of keywords is based on common search terms in Ireland
keywords = ["hotels", "restaurants", "concert tickets", "gigs", "pubs"]
pytrends.build_payload(keywords, geo='IE', timeframe='2010-01-01 2025-01-01')

df_trends = pytrends.interest_over_time()

project_root = '/content/economic_search_project'  # Ensure project_root is defined or accessible
output_path = os.path.join(project_root, 'data/raw', 'google_trends.csv')
df_trends.to_csv(output_path)

"""Increase number of key words

### **Aggregate the google trends into quarterly format**

This ensures that the high frequency data is in line with the quarterly GDP
"""

df_quarterly = df_trends.resample('Q').mean()

"""### **Save data in data/processed folder**"""

import os

output_path_processed = os.path.join(project_root, 'data/processed', 'quarterly_google_trends.csv')
df_quarterly.to_csv(output_path_processed)

print(f"Quarterly aggregated trends saved to: {output_path_processed}")

"""### **Merge the two data sets**"""

import pandas as pd

# Load the GDP data from the uploaded CSV
gdp_df = pd.read_csv(destination_path)

# Process the GDP data:
# Convert 'Quarter' column to datetime, setting it as the index
gdp_df['Quarter'] = pd.PeriodIndex(gdp_df['Quarter'], freq='Q').to_timestamp(how='end').normalize()
gdp_df = gdp_df.set_index('Quarter')

# Select the 'VALUE' column and rename it to 'GDP'
gdp_df = gdp_df[['VALUE']]
gdp_df.rename(columns={'VALUE': 'GDP'}, inplace=True)

# Rename the index to 'date' to match the index name of df_quarterly for a clean merge
gdp_df.index.name = 'date'

# Merge the two dataframes
df = pd.merge(gdp_df, df_quarterly, left_index=True, right_index=True)
print("Merged DataFrame using pd.merge():")
print(df.head()) # Changed from print(pd.merge) to print(df.head()) to show the merged dataframe

"""# Investigate Correlations

###**The correlations between the individual search terms and GDP**
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Calculate the correlation matrix
correlation_matrix = df.corr(numeric_only=True)

# Display the correlation matrix
print("Correlation Matrix:")
display(correlation_matrix)

"""###**Correlation matrix for past five years**"""

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Determine the start date for the last five years
five_years_ago = df.index.max() - pd.DateOffset(years=5)

# Filter the DataFrame for the last five years
df_last_5_years = df[df.index >= five_years_ago]

# Select relevant columns for correlation (GDP and keywords)
correlation_columns = ['GDP'] + keywords
df_corr_subset = df_last_5_years[correlation_columns]

# Calculate the correlation matrix for the last 5 years
correlation_matrix_5_years = df_corr_subset.corr(numeric_only=True)

# Display the correlation matrix
print("Correlation Matrix for Last 5 Years:")
display(correlation_matrix_5_years)

# Visualize the correlation matrix using a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix_5_years, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of GDP and Google Trends Data (Last 5 Years)')
plt.show()

"""###**Saving the correlation matrices to results folder**"""

import os

results_folder = os.path.join(project_root, 'results')

# Save the full correlation matrix
output_path_full_corr = os.path.join(results_folder, 'full_correlation_matrix.csv')
correlation_matrix.to_csv(output_path_full_corr)
print(f"Full correlation matrix saved to: {output_path_full_corr}")

# Save the 5-year correlation matrix
output_path_5yr_corr = os.path.join(results_folder, 'five_year_correlation_matrix.csv')
correlation_matrix_5_years.to_csv(output_path_5yr_corr)
print(f"5-year correlation matrix saved to: {output_path_5yr_corr}")

"""### **Create hospitality activity index using Google trends key words**

The use of PCA creates a hospitality index which captures the effect of the key words
"""

from sklearn.decomposition import PCA

pca = PCA(n_components=1)
df['hospitality_index'] = pca.fit_transform(df_quarterly[keywords])
# -*- coding: utf-8 -*-
"""Organise data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HL9_Lp5MeFbTL3duxgDcBDRbm87_yuoB

# Create Folders
"""

import os

project_root = "/content/economic_search_project"

folders = [
    "data/raw",
    "data/processed",
    "analysis",
    "notebooks",
    "results",
    "models",
    "docs"
]

for folder in folders:
    os.makedirs(os.path.join(project_root, folder), exist_ok=True)

project_root

"""# Gather Data

### **Upload quarterly GDP**
"""

import os
from google.colab import files
import shutil

# Upload the file
uploaded = files.upload()

# Get the name of the uploaded file
for filename in uploaded.keys():
    uploaded_filename = filename
    print(f'User uploaded file "{uploaded_filename}" with length {len(uploaded[filename])} bytes')

project_root = '/content/economic_search_project' # Assuming project_root is defined as in the previous cell
target_folder = os.path.join(project_root, 'data/raw')

# Move the uploaded file to the target folder
if 'uploaded_filename' in locals():
    destination_path = os.path.join(target_folder, uploaded_filename)
    shutil.move(uploaded_filename, destination_path)
    print(f'Moved "{uploaded_filename}" to "{destination_path}"')
else:
    print("No file was uploaded.")

"""### **Collecting data on google search trends using hospitality key words and saving as CSV file in raw data folder**




"""

!pip install pytrends
from pytrends.request import TrendReq
import pandas as pd
import os

pytrends = TrendReq()

keywords = ["hotels", "restaurants", "concert tickets", "gigs", "pubs"]
pytrends.build_payload(keywords, geo='IE', timeframe='2010-01-01 2025-01-01')

df_trends = pytrends.interest_over_time()

project_root = '/content/economic_search_project' # Ensure project_root is defined or accessible
output_path = os.path.join(project_root, 'data/raw', 'google_trends.csv')
df_trends.to_csv(output_path)

"""Increase number of key words

### **Aggregate the google trends into quarterly format**
"""

df_quarterly = df_trends.resample('Q').mean()

"""### **Save data in data/processed folder**"""

import os

output_path_processed = os.path.join(project_root, 'data/processed', 'quarterly_google_trends.csv')
df_quarterly.to_csv(output_path_processed)

print(f"Quarterly aggregated trends saved to: {output_path_processed}")

"""### **Merge the two data sets**"""

import pandas as pd

# Load the GDP data from the uploaded CSV
gdp_df = pd.read_csv(destination_path)

# Process the GDP data:
# Convert 'Quarter' column to datetime, setting it as the index
gdp_df['Quarter'] = pd.PeriodIndex(gdp_df['Quarter'], freq='Q').to_timestamp(how='end').normalize()
gdp_df = gdp_df.set_index('Quarter')

# Select the 'VALUE' column and rename it to 'GDP'
gdp_df = gdp_df[['VALUE']]
gdp_df.rename(columns={'VALUE': 'GDP'}, inplace=True)

# Rename the index to 'date' to match the index name of df_quarterly for a clean merge
gdp_df.index.name = 'date'

# Merge the two dataframes
df = pd.merge(gdp_df, df_quarterly, left_index=True, right_index=True)
print("Merged DataFrame using pd.merge():")
print(pd.merge)

"""### **Create hospitality activity index using Google trends key words**"""

from sklearn.decomposition import PCA

pca = PCA(n_components=1)
df['hospitality_index'] = pca.fit_transform(df_quarterly[keywords])